# âœ‹ AirSketch

> **Transform your hands into digital brushes** - An AI-powered computer vision application that turns hand gestures into interactive drawing and gesture recognition experiences.

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![OpenCV](https://img.shields.io/badge/OpenCV-4.11.0-green.svg)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.19.1-orange.svg)
![MediaPipe](https://img.shields.io/badge/MediaPipe-0.10.21-red.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

## ğŸ¯ Feature Demo

| ğŸ¨ Air Drawing | ğŸ¤– Gesture Recognition |
|:-------------:|:---------------------:|
| <img src="demo/drawing1-ezgif.com-crop.gif" alt="Drawing Demo" width="350"/> | <img src="demo/detection-ezgif.com-crop.gif" alt="Gesture Demo" width="350"/> |
| Draw with hand gestures | Real-time gesture detection |

## ğŸ“º Video Tutorial

<div align="center">
  <a href="https://youtu.be/uzM4oFQPDSo?si=4UzegIuCdZJ0oa4z">
    <img src="https://img.shields.io/badge/â–¶ï¸_Watch_Tutorial-FF0000?style=for-the-badge&logo=youtube&logoColor=white" alt="YouTube Tutorial"/>
  </a>
  <p><em>ğŸš€ Complete walkthrough of AirSketch - from setup to creating your own dataset and training a new model!</em></p>
</div>

**What you'll learn:**
- ğŸ› ï¸ Project setup and installation
- ğŸ¯ Understanding the codebase structure
- ğŸ¨ How to use all drawing and detection modes
- ğŸ§  Training your own gesture models

## ğŸ¨ What is AirSketch?

AirSketch is a revolutionary computer vision application that bridges the gap between physical gestures and digital interaction. Using advanced machine learning models and real-time hand tracking, it transforms your webcam into a powerful tool for:

- **âœï¸ Air Drawing** - Draw in mid-air using hand gestures
- **ğŸ¤– Gesture Recognition** - Train and recognize custom hand gestures
- **ğŸ“Š Dataset Creation** - Build your own gesture datasets with ease
- **ğŸ¥ Recording & Analysis** - Capture and analyze your interactions

## ğŸš€ Features

### ğŸ¯ Multiple Operation Modes

| Mode | Description | Key |
|------|-------------|-----|
| **Landmark** | Basic hand tracking with joint visualization | `E` |
| **Detection** | Custom gesture recognition and classification | `Q` |
| **Drawing** | Air drawing with pen/eraser gestures | `W` |
| **Dataset** | Interactive dataset creation for training | `D` |

### ğŸ¨ Drawing Capabilities
- **Pen Mode**: Draw smooth green lines in the air
- **Eraser Mode**: Remove drawings with finger gestures
- **Canvas Management**: Clear, save, and manipulate your artwork
- **Real-time Feedback**: Visual indicators for active tools

### ğŸ§  AI-Powered Recognition
- **TensorFlow Lite Models**: Optimized for real-time performance
- **Anomaly Detection**: Autoencoder-based gesture validation
- **Custom Training**: Build models for your specific gestures
- **Confidence Scoring**: Reliability metrics for predictions

### ğŸ“Š Dataset Creation Tools
- **Manual Mode**: Capture specific gesture samples on-demand
- **Automatic Mode**: Continuous data collection for training
- **Label Management**: Interactive labeling system
- **CSV Export**: Ready-to-use datasets for machine learning

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8 or higher
- Webcam or camera device
- 4GB+ RAM recommended

### Quick Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/AirSketch.git
cd AirSketch

# Install dependencies
pip install -r requirements.txt

# Run the application
python main_app.py
```

### Dependencies
- **OpenCV**: Computer vision and image processing
- **MediaPipe**: Hand landmark detection
- **TensorFlow**: Machine learning models
- **NumPy/Pandas**: Data manipulation
- **Scikit-learn**: Model utilities

## ğŸ® Usage Guide

### Getting Started
1. **Launch**: Run `python main_app.py`
2. **Camera Setup**: Ensure your webcam is connected
3. **Hand Position**: Place your hand in front of the camera
4. **Mode Selection**: Use keyboard shortcuts to switch modes

### Keyboard Controls

```
ğŸ¯ Mode Switching
E - Landmark Mode (hand tracking only)
Q - Detection Mode (gesture recognition)
W - Drawing Mode (air drawing)
D - Dataset Mode (data collection)

ğŸ¨ Drawing Controls
C - Clear canvas
SPACE - Capture gesture (dataset mode)

ğŸ“¹ Recording
R - Start/Stop video recording

ğŸ”§ Dataset Tools
M - Toggle manual capture mode
L - Change label (manual mode)

âš¡ General
ESC - Exit application
```

### Drawing Mode Tutorial
1. Press `W` to enter drawing mode
2. Make a **"pen"** gesture to start drawing
3. Make an **"eraser"** gesture to erase
4. Use `C` to clear the entire canvas

### Creating Custom Gestures
1. Press `D` to enter dataset mode
2. Enter a label for your gesture
3. Press `SPACE` to start/stop data collection
4. Perform your gesture repeatedly
5. Train your model using the Jupyter notebooks

## ğŸ“ Project Structure

```
AirSketch/
â”œâ”€â”€ ğŸ¯ Core Application
â”‚   â”œâ”€â”€ main_app.py              # Main application entry point
â”‚   â”œâ”€â”€ gesture_predictor.py     # Gesture recognition engine
â”‚   â”œâ”€â”€ drawing_handler.py       # Air drawing functionality
â”‚   â”œâ”€â”€ dataset_creator.py       # Dataset collection tools
â”‚   â”œâ”€â”€ ui_handler.py           # User interface components
â”‚   â””â”€â”€ utils.py                # Utility functions
â”‚
â”œâ”€â”€ ğŸ§  AI Models
â”‚   â”œâ”€â”€ models/                 # Trained models
â”‚   â”‚   â”œâ”€â”€ tflite/            # Optimized TensorFlow Lite models
â”‚   â”‚   â”œâ”€â”€ gesture_classifier.h5
â”‚   â”‚   â””â”€â”€ autoencoder.keras
â”‚   â””â”€â”€ drawing_models/        # Drawing-specific models
â”‚
â”œâ”€â”€ ğŸ“Š Data & Training
â”‚   â”œâ”€â”€ data/                  # Generated datasets
â”‚   â”œâ”€â”€ notebooks/             # Jupyter training notebooks
â”‚   â”‚   â”œâ”€â”€ neural_network.ipynb
â”‚   â”‚   â”œâ”€â”€ auto_encoder.ipynb
â”‚   â”‚   â””â”€â”€ data-exploration.ipynb
â”‚   â””â”€â”€ recordings/            # Video recordings
â”‚
â””â”€â”€ ğŸ“‹ Configuration
    â”œâ”€â”€ requirements.txt       # Python dependencies
    â””â”€â”€ README.md             # This file
```

## ğŸ§ª Model Training

AirSketch includes comprehensive Jupyter notebooks for training your own models:

### 1. Data Exploration (`data-exploration.ipynb`)
- Analyze collected gesture data
- Visualize hand landmark patterns
- Identify data quality issues

### 2. Neural Network Training (`neural_network.ipynb`)
- Train gesture classification models
- Hyperparameter optimization
- Performance evaluation

### 3. Autoencoder Training (`auto_encoder.ipynb`)
- Build anomaly detection models
- Threshold optimization
- Gesture validation

## ğŸ¯ Advanced Features

### Real-time Performance
- **High FPS**: Optimized for smooth real-time interaction
- **TensorFlow Lite**: Mobile-optimized model inference

### Gesture Validation
- **Autoencoder Filtering**: Reject invalid or unknown gestures
- **Confidence Thresholding**: Adjustable prediction confidence
- **Anomaly Detection**: Identify out-of-distribution inputs

### Data Collection
- **Smart Sampling**: Automatic frame interval optimization
- **Label Validation**: Interactive confirmation system

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **ğŸ› Bug Reports**: Found an issue? Open a GitHub issue
2. **ğŸ’¡ Feature Requests**: Have an idea? We'd love to hear it
3. **ğŸ”§ Code Contributions**: Fork, develop, and submit a PR
4. **ğŸ“š Documentation**: Help improve our docs and tutorials

### Development Setup
```bash
# Fork and clone your fork
git clone https://github.com/yourusername/AirSketch.git

# Create a feature branch
git checkout -b feature/amazing-feature

# Make your changes and commit
git commit -m "Add amazing feature"

# Push and create a PR
git push origin feature/amazing-feature
```

## ğŸ”§ Troubleshooting

### Common Issues

**Camera not detected**
```bash
# Check available cameras
python -c "import cv2; print([i for i in range(10) if cv2.VideoCapture(i).read()[0]])"
```

**Model loading errors**
- Ensure all model files are in the correct directories
- Check TensorFlow installation: `pip install tensorflow==2.19.1`

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **MediaPipe Team** - For excellent hand tracking capabilities
- **TensorFlow Team** - For powerful ML framework
- **OpenCV Community** - For computer vision tools

## ğŸŒŸ Star History

If you find AirSketch useful, please consider giving it a star! â­

---

**Made with â¤ï¸ by Hassan Kalantari**

*Transform your gestures into digital magic* âœ¨